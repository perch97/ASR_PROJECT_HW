{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUyFOcTYUWqQ",
        "outputId": "f29a632c-7860-497a-81e1-cfa4f1248c12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'asr_hw'...\n",
            "remote: Enumerating objects: 123, done.\u001b[K\n",
            "remote: Counting objects: 100% (123/123), done.\u001b[K\n",
            "remote: Compressing objects: 100% (117/117), done.\u001b[K\n",
            "remote: Total 123 (delta 25), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (123/123), 52.77 KiB | 457.00 KiB/s, done.\n",
            "Resolving deltas: 100% (25/25), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/perch97/asr_hw.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf asr_hw"
      ],
      "metadata": {
        "id": "7phPLD6aYi1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd asr_hw\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PruiWk6SUZax",
        "outputId": "a03bd3da-f43f-4884-8bd1-9fdd8cd39203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/asr_hw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -r requirements.txt\n",
        "# !pip install wandb\n",
        "# !pip install hydra-core\n"
      ],
      "metadata": {
        "id": "B8L5fxhnU4RC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login(key='3d48fdc51539c8f726de78a258609f12c27e33e5') # Pass the API key using the 'key' keyword argument"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FDHby1HU6sS",
        "outputId": "3466f56c-2bee-4540-e64e-52de63f5670f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvadim-smir97\u001b[0m (\u001b[33mvadim-smir97-simon-fraser-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_API_KEY\"] = \"3d48fdc51539c8f726de78a258609f12c27e33e5\""
      ],
      "metadata": {
        "id": "YIKTwLRuU-qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train.py -cn=train_argmax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd2kiPPBVBfD",
        "outputId": "7fd13475-12ff-4bf9-9b15-3bcb52c4b024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding save directory '/content/asr_hw/training/testing'...\n",
            "Logging git commit and patch...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvadim-smir97\u001b[0m (\u001b[33mvadim-smir97-simon-fraser-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/asr_hw/wandb/run-20250123_045152-9cwgliuq\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtesting\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/vadim-smir97-simon-fraser-university/ASR_HW\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vadim-smir97-simon-fraser-university/ASR_HW/runs/9cwgliuq\u001b[0m\n",
            "/usr/local/lib/python3.11/dist-packages/torch_audiomentations/core/transforms_interface.py:76: FutureWarning: Transforms now expect an `output_type` argument that currently defaults to 'tensor', will default to 'dict' in v0.12, and will be removed in v0.13. Make sure to update your code to something like:\n",
            "  >>> augment = AddColoredNoise(..., output_type='dict')\n",
            "  >>> augmented_samples = augment(samples).samples\n",
            "  warnings.warn(\n",
            "DeepSpeech2(\n",
            "  (conv_block): ConvBlock(\n",
            "    (conv_block): Sequential(\n",
            "      (0): Conv2d(1, 32, kernel_size=(41, 11), stride=(2, 2), padding=(20, 5))\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): Hardtanh(min_val=0, max_val=20, inplace=True)\n",
            "      (3): Conv2d(32, 32, kernel_size=(21, 11), stride=(2, 1), padding=(10, 5))\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): Hardtanh(min_val=0, max_val=20, inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (gru_layers): Sequential(\n",
            "    (0): GRUBlock(\n",
            "      (gru): GRU(1024, 1024, batch_first=True, bidirectional=True)\n",
            "    )\n",
            "    (1): BatchNormT(\n",
            "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): GRUBlock(\n",
            "      (gru): GRU(1024, 1024, batch_first=True, bidirectional=True)\n",
            "    )\n",
            "    (3): BatchNormT(\n",
            "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (4): GRUBlock(\n",
            "      (gru): GRU(1024, 1024, batch_first=True, bidirectional=True)\n",
            "    )\n",
            "    (5): BatchNormT(\n",
            "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (6): GRUBlock(\n",
            "      (gru): GRU(1024, 1024, batch_first=True, bidirectional=True)\n",
            "    )\n",
            "    (7): BatchNormT(\n",
            "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (8): GRUBlock(\n",
            "      (gru): GRU(1024, 1024, batch_first=True, bidirectional=True)\n",
            "    )\n",
            "  )\n",
            "  (batch_norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc): Linear(in_features=1024, out_features=28, bias=False)\n",
            ")\n",
            "All parameters: 63266080\n",
            "Trainable parameters: 63266080\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 1 [0/200 (0%)] Loss: 6.706394\n",
            "train:  12% 25/200 [00:14<01:19,  2.20it/s]Train Epoch: 1 [25/200 (12%)] Loss: 3.763893\n",
            "train:  25% 50/200 [00:25<01:04,  2.32it/s]Train Epoch: 1 [50/200 (25%)] Loss: 3.370931\n",
            "train:  38% 75/200 [00:37<00:56,  2.23it/s]Train Epoch: 1 [75/200 (38%)] Loss: 3.371812\n",
            "train:  50% 100/200 [00:49<00:44,  2.26it/s]Train Epoch: 1 [100/200 (50%)] Loss: 2.996747\n",
            "train:  62% 125/200 [01:00<00:33,  2.23it/s]Train Epoch: 1 [125/200 (62%)] Loss: 2.854184\n",
            "train:  75% 150/200 [01:12<00:22,  2.23it/s]Train Epoch: 1 [150/200 (75%)] Loss: 2.838579\n",
            "train:  88% 175/200 [01:24<00:11,  2.23it/s]Train Epoch: 1 [175/200 (88%)] Loss: 2.746811\n",
            "train: 100% 199/200 [01:35<00:00,  2.08it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.82it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.35it/s]\n",
            "    epoch          : 1\n",
            "    loss           : 2.7848563766479493\n",
            "    grad_norm      : 2.2236318397521972\n",
            "    val_loss       : 2.8065823975731345\n",
            "    val_CER_(Argmax): 0.685430869070109\n",
            "    val_WER_(Argmax): 1.0410876469543855\n",
            "    test_loss      : 2.7996708096527474\n",
            "    test_CER_(Argmax): 0.6806664440881192\n",
            "    test_WER_(Argmax): 1.047868176018258\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 2 [0/200 (0%)] Loss: 2.688246\n",
            "train:  12% 25/200 [00:11<01:17,  2.27it/s]Train Epoch: 2 [25/200 (12%)] Loss: 2.787285\n",
            "train:  25% 50/200 [00:24<01:06,  2.26it/s]Train Epoch: 2 [50/200 (25%)] Loss: 2.408979\n",
            "train:  38% 75/200 [00:35<00:56,  2.23it/s]Train Epoch: 2 [75/200 (38%)] Loss: 2.157398\n",
            "train:  50% 100/200 [00:47<00:44,  2.26it/s]Train Epoch: 2 [100/200 (50%)] Loss: 2.017089\n",
            "train:  62% 125/200 [00:59<00:33,  2.27it/s]Train Epoch: 2 [125/200 (62%)] Loss: 1.917047\n",
            "train:  75% 150/200 [01:10<00:22,  2.25it/s]Train Epoch: 2 [150/200 (75%)] Loss: 1.735098\n",
            "train:  88% 175/200 [01:22<00:11,  2.22it/s]Train Epoch: 2 [175/200 (88%)] Loss: 1.675285\n",
            "train: 100% 199/200 [01:34<00:00,  2.12it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.51it/s]\n",
            "test: 100% 82/82 [00:06<00:00, 11.81it/s]\n",
            "    epoch          : 2\n",
            "    loss           : 1.7630453205108643\n",
            "    grad_norm      : 3.228057279586792\n",
            "    val_loss       : 1.6613790974897498\n",
            "    val_CER_(Argmax): 0.4780346938941517\n",
            "    val_WER_(Argmax): 1.0031560408601274\n",
            "    test_loss      : 1.6242286025024042\n",
            "    test_CER_(Argmax): 0.4704842182649568\n",
            "    test_WER_(Argmax): 0.9995223467537295\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 3 [0/200 (0%)] Loss: 1.609640\n",
            "train:  12% 25/200 [00:12<01:18,  2.23it/s]Train Epoch: 3 [25/200 (12%)] Loss: 1.517338\n",
            "train:  25% 50/200 [00:24<01:08,  2.18it/s]Train Epoch: 3 [50/200 (25%)] Loss: 1.542479\n",
            "train:  38% 75/200 [00:36<00:55,  2.25it/s]Train Epoch: 3 [75/200 (38%)] Loss: 1.455970\n",
            "train:  50% 100/200 [00:47<00:44,  2.25it/s]Train Epoch: 3 [100/200 (50%)] Loss: 1.369084\n",
            "train:  62% 125/200 [00:59<00:33,  2.21it/s]Train Epoch: 3 [125/200 (62%)] Loss: 1.384745\n",
            "train:  75% 150/200 [01:10<00:22,  2.27it/s]Train Epoch: 3 [150/200 (75%)] Loss: 1.260308\n",
            "train:  88% 175/200 [01:22<00:11,  2.20it/s]Train Epoch: 3 [175/200 (88%)] Loss: 1.187554\n",
            "train: 100% 199/200 [01:34<00:00,  2.11it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 12.10it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.31it/s]\n",
            "    epoch          : 3\n",
            "    loss           : 1.3064907455444337\n",
            "    grad_norm      : 2.4085532999038697\n",
            "    val_loss       : 1.2457905026043163\n",
            "    val_CER_(Argmax): 0.37235012809123047\n",
            "    val_WER_(Argmax): 0.8862789801136716\n",
            "    test_loss      : 1.2143352918508576\n",
            "    test_CER_(Argmax): 0.3632135940415818\n",
            "    test_WER_(Argmax): 0.8730848183388099\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 4 [0/200 (0%)] Loss: 1.170093\n",
            "train:  12% 25/200 [00:12<01:18,  2.24it/s]Train Epoch: 4 [25/200 (12%)] Loss: 1.354978\n",
            "train:  25% 50/200 [00:24<01:06,  2.25it/s]Train Epoch: 4 [50/200 (25%)] Loss: 1.167591\n",
            "train:  38% 75/200 [00:36<00:55,  2.25it/s]Train Epoch: 4 [75/200 (38%)] Loss: 1.078239\n",
            "train:  50% 100/200 [00:47<00:44,  2.24it/s]Train Epoch: 4 [100/200 (50%)] Loss: 1.134951\n",
            "train:  62% 125/200 [00:59<00:32,  2.28it/s]Train Epoch: 4 [125/200 (62%)] Loss: 1.086058\n",
            "train:  75% 150/200 [01:10<00:22,  2.22it/s]Train Epoch: 4 [150/200 (75%)] Loss: 1.064811\n",
            "train:  88% 175/200 [01:22<00:11,  2.24it/s]Train Epoch: 4 [175/200 (88%)] Loss: 1.061601\n",
            "train: 100% 199/200 [01:34<00:00,  2.11it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.55it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.54it/s]\n",
            "    epoch          : 4\n",
            "    loss           : 1.0366196656227111\n",
            "    grad_norm      : 1.8819579887390137\n",
            "    val_loss       : 1.026151363288655\n",
            "    val_CER_(Argmax): 0.3152387220790199\n",
            "    val_WER_(Argmax): 0.7968761514612865\n",
            "    test_loss      : 0.9908122187707482\n",
            "    test_CER_(Argmax): 0.3047219939139762\n",
            "    test_WER_(Argmax): 0.7777409669749612\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 5 [0/200 (0%)] Loss: 1.023334\n",
            "train:  12% 25/200 [00:12<01:17,  2.25it/s]Train Epoch: 5 [25/200 (12%)] Loss: 0.958618\n",
            "train:  25% 50/200 [00:24<01:06,  2.25it/s]Train Epoch: 5 [50/200 (25%)] Loss: 0.875575\n",
            "train:  38% 75/200 [00:35<00:54,  2.30it/s]Train Epoch: 5 [75/200 (38%)] Loss: 0.979844\n",
            "train:  50% 100/200 [00:48<00:45,  2.19it/s]Train Epoch: 5 [100/200 (50%)] Loss: 0.868218\n",
            "train:  62% 125/200 [00:59<00:33,  2.21it/s]Train Epoch: 5 [125/200 (62%)] Loss: 0.853096\n",
            "train:  75% 150/200 [01:11<00:22,  2.21it/s]Train Epoch: 5 [150/200 (75%)] Loss: 0.859696\n",
            "train:  88% 175/200 [01:23<00:11,  2.23it/s]Train Epoch: 5 [175/200 (88%)] Loss: 0.856707\n",
            "train: 100% 199/200 [01:34<00:00,  2.10it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.98it/s]\n",
            "test: 100% 82/82 [00:06<00:00, 11.86it/s]\n",
            "    epoch          : 5\n",
            "    loss           : 0.8221747183799744\n",
            "    grad_norm      : 1.5798235034942627\n",
            "    val_loss       : 0.853158547597773\n",
            "    val_CER_(Argmax): 0.26133332987629176\n",
            "    val_WER_(Argmax): 0.7058224054159576\n",
            "    test_loss      : 0.8411509430989986\n",
            "    test_CER_(Argmax): 0.25599719289964723\n",
            "    test_WER_(Argmax): 0.6936251025364863\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 6 [0/200 (0%)] Loss: 0.828316\n",
            "train:  12% 25/200 [00:13<01:18,  2.24it/s]Train Epoch: 6 [25/200 (12%)] Loss: 0.788558\n",
            "train:  25% 50/200 [00:24<01:06,  2.25it/s]Train Epoch: 6 [50/200 (25%)] Loss: 0.848833\n",
            "train:  38% 75/200 [00:36<00:55,  2.26it/s]Train Epoch: 6 [75/200 (38%)] Loss: 0.807973\n",
            "train:  50% 100/200 [00:47<00:43,  2.28it/s]Train Epoch: 6 [100/200 (50%)] Loss: 0.810319\n",
            "train:  62% 125/200 [00:59<00:33,  2.27it/s]Train Epoch: 6 [125/200 (62%)] Loss: 0.708531\n",
            "train:  75% 150/200 [01:10<00:21,  2.27it/s]Train Epoch: 6 [150/200 (75%)] Loss: 0.733086\n",
            "train:  88% 175/200 [01:22<00:10,  2.29it/s]Train Epoch: 6 [175/200 (88%)] Loss: 0.786221\n",
            "train: 100% 199/200 [01:33<00:00,  2.12it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 12.04it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.39it/s]\n",
            "    epoch          : 6\n",
            "    loss           : 0.7457309746742249\n",
            "    grad_norm      : 1.5806389951705933\n",
            "    val_loss       : 0.7408964353449204\n",
            "    val_CER_(Argmax): 0.22810469102650643\n",
            "    val_WER_(Argmax): 0.6380781696833758\n",
            "    test_loss      : 0.7233577370643616\n",
            "    test_CER_(Argmax): 0.2229639686392392\n",
            "    test_WER_(Argmax): 0.6215839215442844\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 7 [0/200 (0%)] Loss: 0.707554\n",
            "train:  12% 25/200 [00:12<01:17,  2.26it/s]Train Epoch: 7 [25/200 (12%)] Loss: 0.671143\n",
            "train:  25% 50/200 [00:24<01:07,  2.23it/s]Train Epoch: 7 [50/200 (25%)] Loss: 0.719959\n",
            "train:  38% 75/200 [00:36<00:56,  2.23it/s]Train Epoch: 7 [75/200 (38%)] Loss: 0.647113\n",
            "train:  50% 100/200 [00:47<00:44,  2.22it/s]Train Epoch: 7 [100/200 (50%)] Loss: 0.661500\n",
            "train:  62% 125/200 [00:59<00:33,  2.25it/s]Train Epoch: 7 [125/200 (62%)] Loss: 0.634734\n",
            "train:  75% 150/200 [01:11<00:22,  2.25it/s]Train Epoch: 7 [150/200 (75%)] Loss: 0.758559\n",
            "train:  88% 175/200 [01:22<00:11,  2.25it/s]Train Epoch: 7 [175/200 (88%)] Loss: 0.632947\n",
            "train: 100% 199/200 [01:34<00:00,  2.10it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.43it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.60it/s]\n",
            "    epoch          : 7\n",
            "    loss           : 0.6422935128211975\n",
            "    grad_norm      : 1.3952159452438355\n",
            "    val_loss       : 0.655794181543238\n",
            "    val_CER_(Argmax): 0.19863227615097787\n",
            "    val_WER_(Argmax): 0.5854676385472064\n",
            "    test_loss      : 0.6478850688876175\n",
            "    test_CER_(Argmax): 0.19663318245518902\n",
            "    test_WER_(Argmax): 0.5758071125715094\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 8 [0/200 (0%)] Loss: 0.618606\n",
            "train:  12% 25/200 [00:13<01:20,  2.19it/s]Train Epoch: 8 [25/200 (12%)] Loss: 0.716594\n",
            "train:  25% 50/200 [00:25<01:07,  2.24it/s]Train Epoch: 8 [50/200 (25%)] Loss: 0.707786\n",
            "train:  38% 75/200 [00:36<00:55,  2.27it/s]Train Epoch: 8 [75/200 (38%)] Loss: 0.656755\n",
            "train:  50% 100/200 [00:48<00:44,  2.25it/s]Train Epoch: 8 [100/200 (50%)] Loss: 0.536619\n",
            "train:  62% 125/200 [01:00<00:33,  2.25it/s]Train Epoch: 8 [125/200 (62%)] Loss: 0.641957\n",
            "train:  75% 150/200 [01:11<00:22,  2.23it/s]Train Epoch: 8 [150/200 (75%)] Loss: 0.579547\n",
            "train:  88% 175/200 [01:23<00:11,  2.22it/s]Train Epoch: 8 [175/200 (88%)] Loss: 0.590638\n",
            "train: 100% 199/200 [01:34<00:00,  2.10it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 12.08it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.24it/s]\n",
            "    epoch          : 8\n",
            "    loss           : 0.5745226097106934\n",
            "    grad_norm      : 1.2367697477340698\n",
            "    val_loss       : 0.6097086468163658\n",
            "    val_CER_(Argmax): 0.1900110289940784\n",
            "    val_WER_(Argmax): 0.5580003605114582\n",
            "    test_loss      : 0.6025653128943792\n",
            "    test_CER_(Argmax): 0.18521245592392302\n",
            "    test_WER_(Argmax): 0.5454416846711094\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 9 [0/200 (0%)] Loss: 0.615127\n",
            "train:  12% 25/200 [00:12<01:16,  2.28it/s]Train Epoch: 9 [25/200 (12%)] Loss: 0.622211\n",
            "train:  25% 50/200 [00:24<01:06,  2.24it/s]Train Epoch: 9 [50/200 (25%)] Loss: 0.529688\n",
            "train:  38% 75/200 [00:36<00:56,  2.21it/s]Train Epoch: 9 [75/200 (38%)] Loss: 0.494224\n",
            "train:  50% 100/200 [00:47<00:44,  2.27it/s]Train Epoch: 9 [100/200 (50%)] Loss: 0.524911\n",
            "train:  62% 125/200 [00:59<00:33,  2.27it/s]Train Epoch: 9 [125/200 (62%)] Loss: 0.580653\n",
            "train:  75% 150/200 [01:10<00:22,  2.26it/s]Train Epoch: 9 [150/200 (75%)] Loss: 0.530105\n",
            "train:  88% 175/200 [01:22<00:11,  2.21it/s]Train Epoch: 9 [175/200 (88%)] Loss: 0.488624\n",
            "train: 100% 199/200 [01:35<00:00,  2.09it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.73it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.54it/s]\n",
            "    epoch          : 9\n",
            "    loss           : 0.5168739628791809\n",
            "    grad_norm      : 1.1898197889328004\n",
            "    val_loss       : 0.521162940123502\n",
            "    val_CER_(Argmax): 0.15950244463019386\n",
            "    val_WER_(Argmax): 0.4833710182864373\n",
            "    test_loss      : 0.5245795936846152\n",
            "    test_CER_(Argmax): 0.15888793647197647\n",
            "    test_WER_(Argmax): 0.4786548861192687\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 10 [0/200 (0%)] Loss: 0.447021\n",
            "train:  12% 25/200 [00:12<01:17,  2.26it/s]Train Epoch: 10 [25/200 (12%)] Loss: 0.449876\n",
            "train:  25% 50/200 [00:24<01:07,  2.23it/s]Train Epoch: 10 [50/200 (25%)] Loss: 0.379647\n",
            "train:  38% 75/200 [00:35<00:56,  2.19it/s]Train Epoch: 10 [75/200 (38%)] Loss: 0.450188\n",
            "train:  50% 100/200 [00:47<00:44,  2.26it/s]Train Epoch: 10 [100/200 (50%)] Loss: 0.366959\n",
            "train:  62% 125/200 [00:59<00:33,  2.24it/s]Train Epoch: 10 [125/200 (62%)] Loss: 0.444626\n",
            "train:  75% 150/200 [01:10<00:21,  2.28it/s]Train Epoch: 10 [150/200 (75%)] Loss: 0.577321\n",
            "train:  88% 175/200 [01:22<00:10,  2.27it/s]Train Epoch: 10 [175/200 (88%)] Loss: 0.401666\n",
            "train: 100% 199/200 [01:34<00:00,  2.12it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 12.13it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.46it/s]\n",
            "    epoch          : 10\n",
            "    loss           : 0.4309946691989899\n",
            "    grad_norm      : 1.1403189182281495\n",
            "    val_loss       : 0.5094957555041594\n",
            "    val_CER_(Argmax): 0.15267095049072119\n",
            "    val_WER_(Argmax): 0.46447505668442407\n",
            "    test_loss      : 0.5120426172890314\n",
            "    test_CER_(Argmax): 0.1540100287710237\n",
            "    test_WER_(Argmax): 0.46144396952390027\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 11 [0/200 (0%)] Loss: 0.435368\n",
            "train:  12% 25/200 [00:13<01:16,  2.29it/s]Train Epoch: 11 [25/200 (12%)] Loss: 0.509150\n",
            "train:  25% 50/200 [00:24<01:07,  2.22it/s]Train Epoch: 11 [50/200 (25%)] Loss: 0.489257\n",
            "train:  38% 75/200 [00:36<00:56,  2.22it/s]Train Epoch: 11 [75/200 (38%)] Loss: 0.457475\n",
            "train:  50% 100/200 [00:47<00:45,  2.22it/s]Train Epoch: 11 [100/200 (50%)] Loss: 0.474883\n",
            "train:  62% 125/200 [00:59<00:33,  2.23it/s]Train Epoch: 11 [125/200 (62%)] Loss: 0.432525\n",
            "train:  75% 150/200 [01:11<00:22,  2.24it/s]Train Epoch: 11 [150/200 (75%)] Loss: 0.391943\n",
            "train:  88% 175/200 [01:22<00:10,  2.29it/s]Train Epoch: 11 [175/200 (88%)] Loss: 0.413703\n",
            "train: 100% 199/200 [01:34<00:00,  2.11it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 12.00it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.50it/s]\n",
            "    epoch          : 11\n",
            "    loss           : 0.43941843152046206\n",
            "    grad_norm      : 1.1977415323257445\n",
            "    val_loss       : 0.5048686244908501\n",
            "    val_CER_(Argmax): 0.15223407920210608\n",
            "    val_WER_(Argmax): 0.4664498325139666\n",
            "    test_loss      : 0.5013049077696916\n",
            "    test_CER_(Argmax): 0.1497508897399323\n",
            "    test_WER_(Argmax): 0.45732221944801527\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 12 [0/200 (0%)] Loss: 0.436184\n",
            "train:  12% 25/200 [00:11<01:19,  2.21it/s]Train Epoch: 12 [25/200 (12%)] Loss: 0.445189\n",
            "train:  25% 50/200 [00:23<01:08,  2.18it/s]Train Epoch: 12 [50/200 (25%)] Loss: 0.426059\n",
            "train:  38% 75/200 [00:35<00:56,  2.23it/s]Train Epoch: 12 [75/200 (38%)] Loss: 0.428026\n",
            "train:  50% 100/200 [00:46<00:44,  2.25it/s]Train Epoch: 12 [100/200 (50%)] Loss: 0.377124\n",
            "train:  62% 125/200 [00:58<00:34,  2.20it/s]Train Epoch: 12 [125/200 (62%)] Loss: 0.356389\n",
            "train:  75% 150/200 [01:10<00:22,  2.25it/s]Train Epoch: 12 [150/200 (75%)] Loss: 0.366153\n",
            "train:  88% 175/200 [01:21<00:11,  2.25it/s]Train Epoch: 12 [175/200 (88%)] Loss: 0.382375\n",
            "train: 100% 199/200 [01:33<00:00,  2.13it/s]\n",
            "val: 100% 85/85 [00:06<00:00, 12.15it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.54it/s]\n",
            "    epoch          : 12\n",
            "    loss           : 0.40001553773880005\n",
            "    grad_norm      : 1.045947048664093\n",
            "    val_loss       : 0.45463659588028404\n",
            "    val_CER_(Argmax): 0.1373425904329325\n",
            "    val_WER_(Argmax): 0.4222325939027919\n",
            "    test_loss      : 0.45998206262181446\n",
            "    test_CER_(Argmax): 0.1362625490591845\n",
            "    test_WER_(Argmax): 0.4148825431061021\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 13 [0/200 (0%)] Loss: 0.362202\n",
            "train:  12% 25/200 [00:13<01:17,  2.25it/s]Train Epoch: 13 [25/200 (12%)] Loss: 0.342256\n",
            "train:  25% 50/200 [00:24<01:07,  2.23it/s]Train Epoch: 13 [50/200 (25%)] Loss: 0.404530\n",
            "train:  38% 75/200 [00:36<00:55,  2.24it/s]Train Epoch: 13 [75/200 (38%)] Loss: 0.389853\n",
            "train:  50% 100/200 [00:47<00:44,  2.25it/s]Train Epoch: 13 [100/200 (50%)] Loss: 0.381945\n",
            "train:  62% 125/200 [00:59<00:33,  2.25it/s]Train Epoch: 13 [125/200 (62%)] Loss: 0.401951\n",
            "train:  75% 150/200 [01:11<00:21,  2.28it/s]Train Epoch: 13 [150/200 (75%)] Loss: 0.472363\n",
            "train:  88% 175/200 [01:22<00:11,  2.23it/s]Train Epoch: 13 [175/200 (88%)] Loss: 0.527512\n",
            "train: 100% 199/200 [01:34<00:00,  2.11it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.70it/s]\n",
            "test: 100% 82/82 [00:06<00:00, 11.75it/s]\n",
            "    epoch          : 13\n",
            "    loss           : 0.41407269835472105\n",
            "    grad_norm      : 1.1145734763145447\n",
            "    val_loss       : 0.45089666527860306\n",
            "    val_CER_(Argmax): 0.13553784430053584\n",
            "    val_WER_(Argmax): 0.4200100564776243\n",
            "    test_loss      : 0.44958016058293787\n",
            "    test_CER_(Argmax): 0.1344818777127827\n",
            "    test_WER_(Argmax): 0.4130391375452376\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 14 [0/200 (0%)] Loss: 0.424495\n",
            "train:  12% 25/200 [00:13<01:18,  2.24it/s]Train Epoch: 14 [25/200 (12%)] Loss: 0.340089\n",
            "train:  25% 50/200 [00:25<01:06,  2.25it/s]Train Epoch: 14 [50/200 (25%)] Loss: 0.397563\n",
            "train:  38% 75/200 [00:37<01:23,  1.50it/s]Train Epoch: 14 [75/200 (38%)] Loss: 0.268702\n",
            "train:  50% 100/200 [00:49<00:44,  2.26it/s]Train Epoch: 14 [100/200 (50%)] Loss: 0.300954\n",
            "train:  62% 125/200 [01:01<00:34,  2.17it/s]Train Epoch: 14 [125/200 (62%)] Loss: 0.315768\n",
            "train:  75% 150/200 [01:12<00:22,  2.19it/s]Train Epoch: 14 [150/200 (75%)] Loss: 0.296350\n",
            "train:  88% 175/200 [01:24<00:10,  2.29it/s]Train Epoch: 14 [175/200 (88%)] Loss: 0.257082\n",
            "train: 100% 199/200 [01:35<00:00,  2.08it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.05it/s]\n",
            "test: 100% 82/82 [00:06<00:00, 11.89it/s]\n",
            "    epoch          : 14\n",
            "    loss           : 0.29691642463207246\n",
            "    grad_norm      : 0.8874334239959717\n",
            "    val_loss       : 0.4087038271567401\n",
            "    val_CER_(Argmax): 0.12026483988729776\n",
            "    val_WER_(Argmax): 0.37432788478373813\n",
            "    test_loss      : 0.4098366800604797\n",
            "    test_CER_(Argmax): 0.11997598636942568\n",
            "    test_WER_(Argmax): 0.3737345469306736\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 15 [0/200 (0%)] Loss: 0.250646\n",
            "train:  12% 25/200 [00:12<01:18,  2.23it/s]Train Epoch: 15 [25/200 (12%)] Loss: 0.350781\n",
            "train:  25% 50/200 [00:23<01:07,  2.21it/s]Train Epoch: 15 [50/200 (25%)] Loss: 0.274912\n",
            "train:  38% 75/200 [00:35<00:54,  2.28it/s]Train Epoch: 15 [75/200 (38%)] Loss: 0.402264\n",
            "train:  50% 100/200 [00:47<00:44,  2.26it/s]Train Epoch: 15 [100/200 (50%)] Loss: 0.364174\n",
            "train:  62% 125/200 [00:58<00:33,  2.23it/s]Train Epoch: 15 [125/200 (62%)] Loss: 0.264350\n",
            "train:  75% 150/200 [01:10<00:22,  2.23it/s]Train Epoch: 15 [150/200 (75%)] Loss: 0.284420\n",
            "train:  88% 175/200 [01:21<00:11,  2.25it/s]Train Epoch: 15 [175/200 (88%)] Loss: 0.265730\n",
            "train: 100% 199/200 [01:33<00:00,  2.13it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.91it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.01it/s]\n",
            "    epoch          : 15\n",
            "    loss           : 0.31491596579551695\n",
            "    grad_norm      : 0.9410108613967896\n",
            "    val_loss       : 0.411279879247441\n",
            "    val_CER_(Argmax): 0.12203150605925228\n",
            "    val_WER_(Argmax): 0.3789029098549163\n",
            "    test_loss      : 0.42293549747001835\n",
            "    test_CER_(Argmax): 0.12355778803597078\n",
            "    test_WER_(Argmax): 0.3765580298203044\n",
            "Saving checkpoint: /content/asr_hw/training/testing/checkpoint-epoch15.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 16 [0/200 (0%)] Loss: 0.264880\n",
            "train:  12% 25/200 [00:11<01:18,  2.24it/s]Train Epoch: 16 [25/200 (12%)] Loss: 0.269326\n",
            "train:  25% 50/200 [00:23<01:08,  2.20it/s]Train Epoch: 16 [50/200 (25%)] Loss: 0.261819\n",
            "train:  38% 75/200 [00:34<00:56,  2.23it/s]Train Epoch: 16 [75/200 (38%)] Loss: 0.317926\n",
            "train:  50% 100/200 [00:46<00:44,  2.25it/s]Train Epoch: 16 [100/200 (50%)] Loss: 0.295065\n",
            "train:  62% 125/200 [00:57<00:33,  2.23it/s]Train Epoch: 16 [125/200 (62%)] Loss: 0.295437\n",
            "train:  75% 150/200 [01:09<00:22,  2.25it/s]Train Epoch: 16 [150/200 (75%)] Loss: 0.237088\n",
            "train:  88% 175/200 [01:21<00:11,  2.25it/s]Train Epoch: 16 [175/200 (88%)] Loss: 0.254489\n",
            "train: 100% 199/200 [01:32<00:00,  2.14it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.67it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.62it/s]\n",
            "    epoch          : 16\n",
            "    loss           : 0.29182311236858366\n",
            "    grad_norm      : 0.8125645279884338\n",
            "    val_loss       : 0.38719998808468087\n",
            "    val_CER_(Argmax): 0.11608717567427441\n",
            "    val_WER_(Argmax): 0.36264569052440154\n",
            "    test_loss      : 0.39352815107601447\n",
            "    test_CER_(Argmax): 0.11445028165260766\n",
            "    test_WER_(Argmax): 0.3557224834720019\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 17 [0/200 (0%)] Loss: 0.281064\n",
            "train:  12% 25/200 [00:14<01:17,  2.27it/s]Train Epoch: 17 [25/200 (12%)] Loss: 0.283388\n",
            "train:  25% 50/200 [00:25<01:06,  2.26it/s]Train Epoch: 17 [50/200 (25%)] Loss: 0.339427\n",
            "train:  38% 75/200 [00:37<00:55,  2.26it/s]Train Epoch: 17 [75/200 (38%)] Loss: 0.291033\n",
            "train:  50% 100/200 [00:49<00:44,  2.22it/s]Train Epoch: 17 [100/200 (50%)] Loss: 0.268380\n",
            "train:  62% 125/200 [01:00<00:33,  2.27it/s]Train Epoch: 17 [125/200 (62%)] Loss: 0.301417\n",
            "train:  75% 150/200 [01:12<00:22,  2.22it/s]Train Epoch: 17 [150/200 (75%)] Loss: 0.317245\n",
            "train:  88% 175/200 [01:24<00:11,  2.23it/s]Train Epoch: 17 [175/200 (88%)] Loss: 0.259693\n",
            "train: 100% 199/200 [01:35<00:00,  2.07it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.92it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.18it/s]\n",
            "    epoch          : 17\n",
            "    loss           : 0.2979742795228958\n",
            "    grad_norm      : 0.8787688612937927\n",
            "    val_loss       : 0.39183854881454916\n",
            "    val_CER_(Argmax): 0.11616211370337717\n",
            "    val_WER_(Argmax): 0.36329211817804896\n",
            "    test_loss      : 0.4008420385965487\n",
            "    test_CER_(Argmax): 0.11618174888597914\n",
            "    test_WER_(Argmax): 0.3567240745577878\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 18 [0/200 (0%)] Loss: 0.302099\n",
            "train:  12% 25/200 [00:11<01:17,  2.25it/s]Train Epoch: 18 [25/200 (12%)] Loss: 0.288876\n",
            "train:  25% 50/200 [00:23<01:06,  2.27it/s]Train Epoch: 18 [50/200 (25%)] Loss: 0.286882\n",
            "train:  38% 75/200 [00:34<00:55,  2.26it/s]Train Epoch: 18 [75/200 (38%)] Loss: 0.302184\n",
            "train:  50% 100/200 [00:46<00:45,  2.21it/s]Train Epoch: 18 [100/200 (50%)] Loss: 0.277167\n",
            "train:  62% 125/200 [00:57<00:33,  2.23it/s]Train Epoch: 18 [125/200 (62%)] Loss: 0.327085\n",
            "train:  75% 150/200 [01:09<00:22,  2.25it/s]Train Epoch: 18 [150/200 (75%)] Loss: 0.378661\n",
            "train:  88% 175/200 [01:21<00:11,  2.21it/s]Train Epoch: 18 [175/200 (88%)] Loss: 0.235037\n",
            "train: 100% 199/200 [01:33<00:00,  2.12it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.51it/s]\n",
            "test: 100% 82/82 [00:06<00:00, 11.73it/s]\n",
            "    epoch          : 18\n",
            "    loss           : 0.26350866615772245\n",
            "    grad_norm      : 0.7894732928276063\n",
            "    val_loss       : 0.3571484337834751\n",
            "    val_CER_(Argmax): 0.10420937187284307\n",
            "    val_WER_(Argmax): 0.3304198859038591\n",
            "    test_loss      : 0.3633581356304448\n",
            "    test_CER_(Argmax): 0.10427301637397915\n",
            "    test_WER_(Argmax): 0.327892458568962\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 19 [0/200 (0%)] Loss: 0.200007\n",
            "train:  12% 25/200 [00:13<01:18,  2.24it/s]Train Epoch: 19 [25/200 (12%)] Loss: 0.209025\n",
            "train:  25% 50/200 [00:25<01:08,  2.20it/s]Train Epoch: 19 [50/200 (25%)] Loss: 0.207745\n",
            "train:  38% 75/200 [00:36<00:56,  2.23it/s]Train Epoch: 19 [75/200 (38%)] Loss: 0.214345\n",
            "train:  50% 100/200 [00:48<00:44,  2.26it/s]Train Epoch: 19 [100/200 (50%)] Loss: 0.258594\n",
            "train:  62% 125/200 [01:00<00:33,  2.27it/s]Train Epoch: 19 [125/200 (62%)] Loss: 0.182749\n",
            "train:  75% 150/200 [01:11<00:21,  2.28it/s]Train Epoch: 19 [150/200 (75%)] Loss: 0.208488\n",
            "train:  88% 175/200 [01:23<00:11,  2.23it/s]Train Epoch: 19 [175/200 (88%)] Loss: 0.201876\n",
            "train: 100% 199/200 [01:34<00:00,  2.09it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 12.09it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.24it/s]\n",
            "    epoch          : 19\n",
            "    loss           : 0.22278307139873504\n",
            "    grad_norm      : 0.7881312012672425\n",
            "    val_loss       : 0.35840502977371214\n",
            "    val_CER_(Argmax): 0.10408184718057178\n",
            "    val_WER_(Argmax): 0.3286273014545327\n",
            "    test_loss      : 0.37046102488913185\n",
            "    test_CER_(Argmax): 0.1046426336087803\n",
            "    test_WER_(Argmax): 0.32552790959426064\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 20 [0/200 (0%)] Loss: 0.195517\n",
            "train:  12% 25/200 [00:13<01:17,  2.25it/s]Train Epoch: 20 [25/200 (12%)] Loss: 0.213848\n",
            "train:  25% 50/200 [00:25<01:06,  2.27it/s]Train Epoch: 20 [50/200 (25%)] Loss: 0.233883\n",
            "train:  38% 75/200 [00:36<00:55,  2.26it/s]Train Epoch: 20 [75/200 (38%)] Loss: 0.301422\n",
            "train:  50% 100/200 [00:48<00:44,  2.26it/s]Train Epoch: 20 [100/200 (50%)] Loss: 0.175708\n",
            "train:  62% 125/200 [01:00<00:32,  2.28it/s]Train Epoch: 20 [125/200 (62%)] Loss: 0.211645\n",
            "train:  75% 150/200 [01:11<00:22,  2.23it/s]Train Epoch: 20 [150/200 (75%)] Loss: 0.203430\n",
            "train:  88% 175/200 [01:23<00:11,  2.23it/s]Train Epoch: 20 [175/200 (88%)] Loss: 0.198166\n",
            "train: 100% 199/200 [01:34<00:00,  2.10it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.44it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.68it/s]\n",
            "    epoch          : 20\n",
            "    loss           : 0.21203861117362977\n",
            "    grad_norm      : 0.7091669011116027\n",
            "    val_loss       : 0.35965197927811565\n",
            "    val_CER_(Argmax): 0.10414741164344225\n",
            "    val_WER_(Argmax): 0.32778591925683565\n",
            "    test_loss      : 0.37368822497565574\n",
            "    test_CER_(Argmax): 0.10520667389324798\n",
            "    test_WER_(Argmax): 0.32571223362583546\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 21 [0/200 (0%)] Loss: 0.209020\n",
            "train:  12% 25/200 [00:13<01:18,  2.23it/s]Train Epoch: 21 [25/200 (12%)] Loss: 0.237992\n",
            "train:  25% 50/200 [00:25<01:07,  2.22it/s]Train Epoch: 21 [50/200 (25%)] Loss: 0.175059\n",
            "train:  38% 75/200 [00:37<00:56,  2.22it/s]Train Epoch: 21 [75/200 (38%)] Loss: 0.162446\n",
            "train:  50% 100/200 [00:48<00:46,  2.16it/s]Train Epoch: 21 [100/200 (50%)] Loss: 0.241655\n",
            "train:  62% 125/200 [01:00<00:33,  2.22it/s]Train Epoch: 21 [125/200 (62%)] Loss: 0.256545\n",
            "train:  75% 150/200 [01:12<00:21,  2.28it/s]Train Epoch: 21 [150/200 (75%)] Loss: 0.231172\n",
            "train:  88% 175/200 [01:24<00:11,  2.21it/s]Train Epoch: 21 [175/200 (88%)] Loss: 0.214849\n",
            "train: 100% 199/200 [01:35<00:00,  2.08it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.60it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.23it/s]\n",
            "    epoch          : 21\n",
            "    loss           : 0.2240069204568863\n",
            "    grad_norm      : 0.7789770889282227\n",
            "    val_loss       : 0.3571177710505093\n",
            "    val_CER_(Argmax): 0.10319778908786077\n",
            "    val_WER_(Argmax): 0.32600755326752445\n",
            "    test_loss      : 0.3709255129825778\n",
            "    test_CER_(Argmax): 0.10312837252013003\n",
            "    test_WER_(Argmax): 0.32156628194232795\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 22 [0/200 (0%)] Loss: 0.265426\n",
            "train:  12% 25/200 [00:13<01:18,  2.23it/s]Train Epoch: 22 [25/200 (12%)] Loss: 0.199511\n",
            "train:  25% 50/200 [00:24<01:06,  2.24it/s]Train Epoch: 22 [50/200 (25%)] Loss: 0.263382\n",
            "train:  38% 75/200 [00:36<00:55,  2.24it/s]Train Epoch: 22 [75/200 (38%)] Loss: 0.256044\n",
            "train:  50% 100/200 [00:48<00:45,  2.20it/s]Train Epoch: 22 [100/200 (50%)] Loss: 0.279747\n",
            "train:  62% 125/200 [00:59<00:33,  2.21it/s]Train Epoch: 22 [125/200 (62%)] Loss: 0.175785\n",
            "train:  75% 150/200 [01:11<00:22,  2.26it/s]Train Epoch: 22 [150/200 (75%)] Loss: 0.260670\n",
            "train:  88% 175/200 [01:23<00:11,  2.24it/s]Train Epoch: 22 [175/200 (88%)] Loss: 0.202182\n",
            "train: 100% 199/200 [01:35<00:00,  2.08it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.65it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 10.81it/s]\n",
            "    epoch          : 22\n",
            "    loss           : 0.21521223664283753\n",
            "    grad_norm      : 0.7399295377731323\n",
            "    val_loss       : 0.3481328876579509\n",
            "    val_CER_(Argmax): 0.09969884903447924\n",
            "    val_WER_(Argmax): 0.3132961506308521\n",
            "    test_loss      : 0.3513230263459973\n",
            "    test_CER_(Argmax): 0.09838570976954236\n",
            "    test_WER_(Argmax): 0.3083017201216246\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 23 [0/200 (0%)] Loss: 0.193912\n",
            "train:  12% 25/200 [00:12<01:18,  2.23it/s]Train Epoch: 23 [25/200 (12%)] Loss: 0.228554\n",
            "train:  25% 50/200 [00:24<01:08,  2.19it/s]Train Epoch: 23 [50/200 (25%)] Loss: 0.202603\n",
            "train:  38% 75/200 [00:37<00:55,  2.23it/s]Train Epoch: 23 [75/200 (38%)] Loss: 0.181005\n",
            "train:  50% 100/200 [00:49<00:45,  2.21it/s]Train Epoch: 23 [100/200 (50%)] Loss: 0.138913\n",
            "train:  62% 125/200 [01:01<00:33,  2.25it/s]Train Epoch: 23 [125/200 (62%)] Loss: 0.175783\n",
            "train:  75% 150/200 [01:12<00:22,  2.22it/s]Train Epoch: 23 [150/200 (75%)] Loss: 0.152569\n",
            "train:  88% 175/200 [01:24<00:11,  2.23it/s]Train Epoch: 23 [175/200 (88%)] Loss: 0.123358\n",
            "train: 100% 199/200 [01:36<00:00,  2.07it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.34it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 10.83it/s]\n",
            "    epoch          : 23\n",
            "    loss           : 0.15950265526771545\n",
            "    grad_norm      : 0.6552385187149048\n",
            "    val_loss       : 0.3389719710630529\n",
            "    val_CER_(Argmax): 0.09513904291332784\n",
            "    val_WER_(Argmax): 0.30037558378213153\n",
            "    test_loss      : 0.34792083937947343\n",
            "    test_CER_(Argmax): 0.09460087706558956\n",
            "    test_WER_(Argmax): 0.2968817729279107\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 24 [0/200 (0%)] Loss: 0.152263\n",
            "train:  12% 25/200 [00:12<01:19,  2.21it/s]Train Epoch: 24 [25/200 (12%)] Loss: 0.188980\n",
            "train:  25% 50/200 [00:24<01:07,  2.24it/s]Train Epoch: 24 [50/200 (25%)] Loss: 0.195390\n",
            "train:  38% 75/200 [00:35<00:56,  2.22it/s]Train Epoch: 24 [75/200 (38%)] Loss: 0.192758\n",
            "train:  50% 100/200 [00:47<00:44,  2.24it/s]Train Epoch: 24 [100/200 (50%)] Loss: 0.142787\n",
            "train:  62% 125/200 [00:59<00:33,  2.25it/s]Train Epoch: 24 [125/200 (62%)] Loss: 0.188264\n",
            "train:  75% 150/200 [01:10<00:22,  2.23it/s]Train Epoch: 24 [150/200 (75%)] Loss: 0.151005\n",
            "train:  88% 175/200 [01:22<00:11,  2.19it/s]Train Epoch: 24 [175/200 (88%)] Loss: 0.211666\n",
            "train: 100% 199/200 [01:34<00:00,  2.11it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.32it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.31it/s]\n",
            "    epoch          : 24\n",
            "    loss           : 0.16783105641603469\n",
            "    grad_norm      : 0.6555532443523407\n",
            "    val_loss       : 0.33750604759244357\n",
            "    val_CER_(Argmax): 0.09319182570614924\n",
            "    val_WER_(Argmax): 0.2948188597994367\n",
            "    test_loss      : 0.34647547508158333\n",
            "    test_CER_(Argmax): 0.09458480903575286\n",
            "    test_WER_(Argmax): 0.29736700968962376\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 25 [0/200 (0%)] Loss: 0.181575\n",
            "train:  12% 25/200 [00:12<01:18,  2.24it/s]Train Epoch: 25 [25/200 (12%)] Loss: 0.151205\n",
            "train:  25% 50/200 [00:24<01:08,  2.20it/s]Train Epoch: 25 [50/200 (25%)] Loss: 0.183089\n",
            "train:  38% 75/200 [00:36<00:56,  2.22it/s]Train Epoch: 25 [75/200 (38%)] Loss: 0.256868\n",
            "train:  50% 100/200 [00:47<00:44,  2.23it/s]Train Epoch: 25 [100/200 (50%)] Loss: 0.150021\n",
            "train:  62% 125/200 [00:59<00:33,  2.22it/s]Train Epoch: 25 [125/200 (62%)] Loss: 0.119891\n",
            "train:  75% 150/200 [01:11<00:22,  2.20it/s]Train Epoch: 25 [150/200 (75%)] Loss: 0.163543\n",
            "train:  88% 175/200 [01:23<00:11,  2.27it/s]Train Epoch: 25 [175/200 (88%)] Loss: 0.123186\n",
            "train: 100% 199/200 [01:34<00:00,  2.10it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 12.02it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.00it/s]\n",
            "    epoch          : 25\n",
            "    loss           : 0.1548417979478836\n",
            "    grad_norm      : 0.6530631983280182\n",
            "    val_loss       : 0.3440301947733935\n",
            "    val_CER_(Argmax): 0.09511614945532006\n",
            "    val_WER_(Argmax): 0.29894656910184203\n",
            "    test_loss      : 0.34961414228125315\n",
            "    test_CER_(Argmax): 0.09318883022482691\n",
            "    test_WER_(Argmax): 0.29739789714117476\n",
            "Saving checkpoint: /content/asr_hw/training/testing/checkpoint-epoch25.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 26 [0/200 (0%)] Loss: 0.198589\n",
            "train:  12% 25/200 [00:11<01:17,  2.25it/s]Train Epoch: 26 [25/200 (12%)] Loss: 0.159309\n",
            "train:  25% 50/200 [00:24<01:07,  2.21it/s]Train Epoch: 26 [50/200 (25%)] Loss: 0.141613\n",
            "train:  38% 75/200 [00:36<00:56,  2.21it/s]Train Epoch: 26 [75/200 (38%)] Loss: 0.262130\n",
            "train:  50% 100/200 [00:47<00:44,  2.24it/s]Train Epoch: 26 [100/200 (50%)] Loss: 0.160318\n",
            "train:  62% 125/200 [00:59<00:33,  2.25it/s]Train Epoch: 26 [125/200 (62%)] Loss: 0.180916\n",
            "train:  75% 150/200 [01:11<00:22,  2.19it/s]Train Epoch: 26 [150/200 (75%)] Loss: 0.147365\n",
            "train:  88% 175/200 [01:22<00:11,  2.20it/s]Train Epoch: 26 [175/200 (88%)] Loss: 0.202278\n",
            "train: 100% 199/200 [01:34<00:00,  2.11it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.16it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.35it/s]\n",
            "    epoch          : 26\n",
            "    loss           : 0.16947675615549088\n",
            "    grad_norm      : 0.7349306428432465\n",
            "    val_loss       : 0.33449387462700114\n",
            "    val_CER_(Argmax): 0.09389203446008226\n",
            "    val_WER_(Argmax): 0.29549680317060567\n",
            "    test_loss      : 0.3449930276085691\n",
            "    test_CER_(Argmax): 0.09428814826097245\n",
            "    test_WER_(Argmax): 0.2953190077128885\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 27 [0/200 (0%)] Loss: 0.166371\n",
            "train:  12% 25/200 [00:11<01:18,  2.23it/s]Train Epoch: 27 [25/200 (12%)] Loss: 0.152230\n",
            "train:  25% 50/200 [00:23<01:06,  2.24it/s]Train Epoch: 27 [50/200 (25%)] Loss: 0.183058\n",
            "train:  38% 75/200 [00:34<00:56,  2.21it/s]Train Epoch: 27 [75/200 (38%)] Loss: 0.132760\n",
            "train:  50% 100/200 [00:46<00:45,  2.22it/s]Train Epoch: 27 [100/200 (50%)] Loss: 0.141990\n",
            "train:  62% 125/200 [00:58<00:33,  2.22it/s]Train Epoch: 27 [125/200 (62%)] Loss: 0.139500\n",
            "train:  75% 150/200 [01:11<00:26,  1.86it/s]Train Epoch: 27 [150/200 (75%)] Loss: 0.102325\n",
            "train:  88% 175/200 [01:22<00:11,  2.23it/s]Train Epoch: 27 [175/200 (88%)] Loss: 0.129645\n",
            "train: 100% 199/200 [01:34<00:00,  2.10it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.85it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.48it/s]\n",
            "    epoch          : 27\n",
            "    loss           : 0.11911725014448166\n",
            "    grad_norm      : 0.5423786115646362\n",
            "    val_loss       : 0.3142487315570607\n",
            "    val_CER_(Argmax): 0.08612542737073928\n",
            "    val_WER_(Argmax): 0.27596100957594255\n",
            "    test_loss      : 0.3287973992708253\n",
            "    test_CER_(Argmax): 0.08680667604607589\n",
            "    test_WER_(Argmax): 0.2746197240215021\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 28 [0/200 (0%)] Loss: 0.099145\n",
            "train:  12% 25/200 [00:13<01:17,  2.25it/s]Train Epoch: 28 [25/200 (12%)] Loss: 0.176304\n",
            "train:  25% 50/200 [00:25<01:07,  2.23it/s]Train Epoch: 28 [50/200 (25%)] Loss: 0.148189\n",
            "train:  38% 75/200 [00:37<00:56,  2.23it/s]Train Epoch: 28 [75/200 (38%)] Loss: 0.101592\n",
            "train:  50% 100/200 [00:49<00:45,  2.22it/s]Train Epoch: 28 [100/200 (50%)] Loss: 0.106197\n",
            "train:  62% 125/200 [01:00<00:33,  2.23it/s]Train Epoch: 28 [125/200 (62%)] Loss: 0.087389\n",
            "train:  75% 150/200 [01:12<00:22,  2.27it/s]Train Epoch: 28 [150/200 (75%)] Loss: 0.101952\n",
            "train:  88% 175/200 [01:24<00:11,  2.20it/s]Train Epoch: 28 [175/200 (88%)] Loss: 0.116304\n",
            "train: 100% 199/200 [01:35<00:00,  2.08it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.49it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 10.79it/s]\n",
            "    epoch          : 28\n",
            "    loss           : 0.10684991121292114\n",
            "    grad_norm      : 0.5568818664550781\n",
            "    val_loss       : 0.31469593521426703\n",
            "    val_CER_(Argmax): 0.08550245962460497\n",
            "    val_WER_(Argmax): 0.2717586268561941\n",
            "    test_loss      : 0.3288951719679484\n",
            "    test_CER_(Argmax): 0.08657849819596884\n",
            "    test_WER_(Argmax): 0.2713177892799306\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 29 [0/200 (0%)] Loss: 0.119442\n",
            "train:  12% 25/200 [00:12<01:20,  2.18it/s]Train Epoch: 29 [25/200 (12%)] Loss: 0.112735\n",
            "train:  25% 50/200 [00:24<01:06,  2.24it/s]Train Epoch: 29 [50/200 (25%)] Loss: 0.111589\n",
            "train:  38% 75/200 [00:36<00:54,  2.28it/s]Train Epoch: 29 [75/200 (38%)] Loss: 0.094375\n",
            "train:  50% 100/200 [00:47<00:44,  2.25it/s]Train Epoch: 29 [100/200 (50%)] Loss: 0.125522\n",
            "train:  62% 125/200 [00:59<00:34,  2.18it/s]Train Epoch: 29 [125/200 (62%)] Loss: 0.127695\n",
            "train:  75% 150/200 [01:11<00:22,  2.22it/s]Train Epoch: 29 [150/200 (75%)] Loss: 0.089230\n",
            "train:  88% 175/200 [01:23<00:11,  2.22it/s]Train Epoch: 29 [175/200 (88%)] Loss: 0.134660\n",
            "train: 100% 199/200 [01:34<00:00,  2.10it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.70it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.54it/s]\n",
            "    epoch          : 29\n",
            "    loss           : 0.1242489543557167\n",
            "    grad_norm      : 0.6152400684356689\n",
            "    val_loss       : 0.31414533257484434\n",
            "    val_CER_(Argmax): 0.085320756504483\n",
            "    val_WER_(Argmax): 0.2720855892069804\n",
            "    test_loss      : 0.32935741961729237\n",
            "    test_CER_(Argmax): 0.08620909240456733\n",
            "    test_WER_(Argmax): 0.27084577697284395\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 30 [0/200 (0%)] Loss: 0.106574\n",
            "train:  12% 25/200 [00:11<01:17,  2.24it/s]Train Epoch: 30 [25/200 (12%)] Loss: 0.121075\n",
            "train:  25% 50/200 [00:23<01:06,  2.26it/s]Train Epoch: 30 [50/200 (25%)] Loss: 0.106302\n",
            "train:  38% 75/200 [00:35<00:56,  2.20it/s]Train Epoch: 30 [75/200 (38%)] Loss: 0.117025\n",
            "train:  50% 100/200 [00:47<00:45,  2.20it/s]Train Epoch: 30 [100/200 (50%)] Loss: 0.139055\n",
            "train:  62% 125/200 [00:58<00:34,  2.19it/s]Train Epoch: 30 [125/200 (62%)] Loss: 0.085259\n",
            "train:  75% 150/200 [01:10<00:22,  2.24it/s]Train Epoch: 30 [150/200 (75%)] Loss: 0.098672\n",
            "train:  88% 175/200 [01:22<00:11,  2.25it/s]Train Epoch: 30 [175/200 (88%)] Loss: 0.119702\n",
            "train: 100% 199/200 [01:34<00:00,  2.11it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.65it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.43it/s]\n",
            "    epoch          : 30\n",
            "    loss           : 0.11880700588226319\n",
            "    grad_norm      : 0.5768993210792541\n",
            "    val_loss       : 0.31405375038876254\n",
            "    val_CER_(Argmax): 0.08354024890654944\n",
            "    val_WER_(Argmax): 0.26605582504568076\n",
            "    test_loss      : 0.32368799389862435\n",
            "    test_CER_(Argmax): 0.08350498933541839\n",
            "    test_WER_(Argmax): 0.2648572252698023\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 31 [0/200 (0%)] Loss: 0.111253\n",
            "train:  12% 25/200 [00:12<01:18,  2.22it/s]Train Epoch: 31 [25/200 (12%)] Loss: 0.178848\n",
            "train:  25% 50/200 [00:24<01:09,  2.17it/s]Train Epoch: 31 [50/200 (25%)] Loss: 0.105036\n",
            "train:  38% 75/200 [00:36<00:56,  2.21it/s]Train Epoch: 31 [75/200 (38%)] Loss: 0.104697\n",
            "train:  50% 100/200 [00:48<00:44,  2.25it/s]Train Epoch: 31 [100/200 (50%)] Loss: 0.142281\n",
            "train:  62% 125/200 [00:59<00:33,  2.26it/s]Train Epoch: 31 [125/200 (62%)] Loss: 0.086746\n",
            "train:  75% 150/200 [01:11<00:21,  2.28it/s]Train Epoch: 31 [150/200 (75%)] Loss: 0.151040\n",
            "train:  88% 175/200 [01:23<00:11,  2.21it/s]Train Epoch: 31 [175/200 (88%)] Loss: 0.076141\n",
            "train: 100% 199/200 [01:35<00:00,  2.09it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.81it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 10.95it/s]\n",
            "    epoch          : 31\n",
            "    loss           : 0.11388947993516922\n",
            "    grad_norm      : 0.5850368642807007\n",
            "    val_loss       : 0.310694040796336\n",
            "    val_CER_(Argmax): 0.08316775206480337\n",
            "    val_WER_(Argmax): 0.26440699043414795\n",
            "    test_loss      : 0.3322004508681414\n",
            "    test_CER_(Argmax): 0.08479355087279408\n",
            "    test_WER_(Argmax): 0.2680160450744236\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 32 [0/200 (0%)] Loss: 0.133394\n",
            "train:  12% 25/200 [00:13<01:18,  2.24it/s]Train Epoch: 32 [25/200 (12%)] Loss: 0.099979\n",
            "train:  25% 50/200 [00:26<01:07,  2.22it/s]Train Epoch: 32 [50/200 (25%)] Loss: 0.081017\n",
            "train:  38% 75/200 [00:38<00:56,  2.21it/s]Train Epoch: 32 [75/200 (38%)] Loss: 0.072766\n",
            "train:  50% 100/200 [00:50<00:45,  2.20it/s]Train Epoch: 32 [100/200 (50%)] Loss: 0.108588\n",
            "train:  62% 125/200 [01:02<00:33,  2.21it/s]Train Epoch: 32 [125/200 (62%)] Loss: 0.081948\n",
            "train:  75% 150/200 [01:13<00:22,  2.23it/s]Train Epoch: 32 [150/200 (75%)] Loss: 0.117787\n",
            "train:  88% 175/200 [01:25<00:11,  2.20it/s]Train Epoch: 32 [175/200 (88%)] Loss: 0.129108\n",
            "train: 100% 199/200 [01:37<00:00,  2.05it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.90it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 10.93it/s]\n",
            "    epoch          : 32\n",
            "    loss           : 0.08379884958267211\n",
            "    grad_norm      : 0.5154381501674652\n",
            "    val_loss       : 0.3210417838657604\n",
            "    val_CER_(Argmax): 0.08387408284843713\n",
            "    val_WER_(Argmax): 0.2655269323739175\n",
            "    test_loss      : 0.33591126868637594\n",
            "    test_CER_(Argmax): 0.0849840703031405\n",
            "    test_WER_(Argmax): 0.2659880520535688\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 33 [0/200 (0%)] Loss: 0.123893\n",
            "train:  12% 25/200 [00:11<01:19,  2.21it/s]Train Epoch: 33 [25/200 (12%)] Loss: 0.089790\n",
            "train:  25% 50/200 [00:23<01:08,  2.20it/s]Train Epoch: 33 [50/200 (25%)] Loss: 0.088671\n",
            "train:  38% 75/200 [00:35<00:55,  2.24it/s]Train Epoch: 33 [75/200 (38%)] Loss: 0.124403\n",
            "train:  50% 100/200 [00:46<00:45,  2.21it/s]Train Epoch: 33 [100/200 (50%)] Loss: 0.075827\n",
            "train:  62% 125/200 [00:58<00:33,  2.21it/s]Train Epoch: 33 [125/200 (62%)] Loss: 0.046595\n",
            "train:  75% 150/200 [01:10<00:22,  2.25it/s]Train Epoch: 33 [150/200 (75%)] Loss: 0.085453\n",
            "train:  88% 175/200 [01:21<00:11,  2.21it/s]Train Epoch: 33 [175/200 (88%)] Loss: 0.039634\n",
            "train: 100% 199/200 [01:33<00:00,  2.12it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.04it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.22it/s]\n",
            "    epoch          : 33\n",
            "    loss           : 0.0746503584086895\n",
            "    grad_norm      : 0.4490239191055298\n",
            "    val_loss       : 0.3127461736693102\n",
            "    val_CER_(Argmax): 0.08090642658704619\n",
            "    val_WER_(Argmax): 0.2586773692604451\n",
            "    test_loss      : 0.32641391147200655\n",
            "    test_CER_(Argmax): 0.08048474597586133\n",
            "    test_WER_(Argmax): 0.2562711979623317\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 34 [0/200 (0%)] Loss: 0.069190\n",
            "train:  12% 25/200 [00:12<01:17,  2.26it/s]Train Epoch: 34 [25/200 (12%)] Loss: 0.077325\n",
            "train:  25% 50/200 [00:23<01:06,  2.24it/s]Train Epoch: 34 [50/200 (25%)] Loss: 0.080859\n",
            "train:  38% 75/200 [00:35<00:56,  2.23it/s]Train Epoch: 34 [75/200 (38%)] Loss: 0.063301\n",
            "train:  50% 100/200 [00:47<00:44,  2.24it/s]Train Epoch: 34 [100/200 (50%)] Loss: 0.120167\n",
            "train:  62% 125/200 [00:59<00:33,  2.22it/s]Train Epoch: 34 [125/200 (62%)] Loss: 0.074363\n",
            "train:  75% 150/200 [01:10<00:22,  2.21it/s]Train Epoch: 34 [150/200 (75%)] Loss: 0.109261\n",
            "train:  88% 175/200 [01:22<00:11,  2.25it/s]Train Epoch: 34 [175/200 (88%)] Loss: 0.082033\n",
            "train: 100% 199/200 [01:34<00:00,  2.11it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.91it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 10.89it/s]\n",
            "    epoch          : 34\n",
            "    loss           : 0.0802795097231865\n",
            "    grad_norm      : 0.48642812252044676\n",
            "    val_loss       : 0.31384071059086743\n",
            "    val_CER_(Argmax): 0.07985198541846582\n",
            "    val_WER_(Argmax): 0.2545213330915629\n",
            "    test_loss      : 0.33172784600316024\n",
            "    test_CER_(Argmax): 0.08050370609488078\n",
            "    test_WER_(Argmax): 0.25543109385459617\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 35 [0/200 (0%)] Loss: 0.078595\n",
            "train:  12% 25/200 [00:13<01:17,  2.24it/s]Train Epoch: 35 [25/200 (12%)] Loss: 0.080906\n",
            "train:  25% 50/200 [00:25<01:06,  2.25it/s]Train Epoch: 35 [50/200 (25%)] Loss: 0.069321\n",
            "train:  38% 75/200 [00:37<00:55,  2.23it/s]Train Epoch: 35 [75/200 (38%)] Loss: 0.080267\n",
            "train:  50% 100/200 [00:48<00:44,  2.24it/s]Train Epoch: 35 [100/200 (50%)] Loss: 0.076297\n",
            "train:  62% 125/200 [01:00<00:34,  2.20it/s]Train Epoch: 35 [125/200 (62%)] Loss: 0.049673\n",
            "train:  75% 150/200 [01:12<00:22,  2.21it/s]Train Epoch: 35 [150/200 (75%)] Loss: 0.085246\n",
            "train:  88% 175/200 [01:24<00:11,  2.20it/s]Train Epoch: 35 [175/200 (88%)] Loss: 0.101959\n",
            "train: 100% 199/200 [01:35<00:00,  2.07it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.66it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 10.67it/s]\n",
            "    epoch          : 35\n",
            "    loss           : 0.08024951800704003\n",
            "    grad_norm      : 0.49123451828956605\n",
            "    val_loss       : 0.3070305620922762\n",
            "    val_CER_(Argmax): 0.07881031552856312\n",
            "    val_WER_(Argmax): 0.24997949832378064\n",
            "    test_loss      : 0.3257076396811299\n",
            "    test_CER_(Argmax): 0.07976073307993486\n",
            "    test_WER_(Argmax): 0.2533625793888262\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 36 [0/200 (0%)] Loss: 0.060394\n",
            "train:  12% 25/200 [00:13<01:18,  2.22it/s]Train Epoch: 36 [25/200 (12%)] Loss: 0.053816\n",
            "train:  25% 50/200 [00:24<01:06,  2.26it/s]Train Epoch: 36 [50/200 (25%)] Loss: 0.158607\n",
            "train:  38% 75/200 [00:36<00:56,  2.22it/s]Train Epoch: 36 [75/200 (38%)] Loss: 0.107529\n",
            "train:  50% 100/200 [00:48<00:44,  2.22it/s]Train Epoch: 36 [100/200 (50%)] Loss: 0.048391\n",
            "train:  62% 125/200 [00:59<00:33,  2.22it/s]Train Epoch: 36 [125/200 (62%)] Loss: 0.056201\n",
            "train:  75% 150/200 [01:12<00:22,  2.19it/s]Train Epoch: 36 [150/200 (75%)] Loss: 0.042379\n",
            "train:  88% 175/200 [01:24<00:10,  2.28it/s]Train Epoch: 36 [175/200 (88%)] Loss: 0.069911\n",
            "train: 100% 199/200 [01:35<00:00,  2.08it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.39it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.46it/s]\n",
            "    epoch          : 36\n",
            "    loss           : 0.061566624119877816\n",
            "    grad_norm      : 0.43587899386882784\n",
            "    val_loss       : 0.3093485388685675\n",
            "    val_CER_(Argmax): 0.07843344112573067\n",
            "    val_WER_(Argmax): 0.2484537355674074\n",
            "    test_loss      : 0.3280933306711476\n",
            "    test_CER_(Argmax): 0.07823975437426864\n",
            "    test_WER_(Argmax): 0.24712957331779947\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 37 [0/200 (0%)] Loss: 0.078573\n",
            "train:  12% 25/200 [00:13<01:18,  2.23it/s]Train Epoch: 37 [25/200 (12%)] Loss: 0.059630\n",
            "train:  25% 50/200 [00:25<01:07,  2.23it/s]Train Epoch: 37 [50/200 (25%)] Loss: 0.050743\n",
            "train:  38% 75/200 [00:37<00:56,  2.22it/s]Train Epoch: 37 [75/200 (38%)] Loss: 0.051081\n",
            "train:  50% 100/200 [00:49<00:45,  2.19it/s]Train Epoch: 37 [100/200 (50%)] Loss: 0.050397\n",
            "train:  62% 125/200 [01:00<00:33,  2.21it/s]Train Epoch: 37 [125/200 (62%)] Loss: 0.056723\n",
            "train:  75% 150/200 [01:12<00:22,  2.23it/s]Train Epoch: 37 [150/200 (75%)] Loss: 0.056344\n",
            "train:  88% 175/200 [01:23<00:11,  2.25it/s]Train Epoch: 37 [175/200 (88%)] Loss: 0.054020\n",
            "train: 100% 199/200 [01:35<00:00,  2.08it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.21it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.30it/s]\n",
            "    epoch          : 37\n",
            "    loss           : 0.06695253118872642\n",
            "    grad_norm      : 0.5170216870307922\n",
            "    val_loss       : 0.3109791694318547\n",
            "    val_CER_(Argmax): 0.07803748101213748\n",
            "    val_WER_(Argmax): 0.24665636141885225\n",
            "    test_loss      : 0.33057847237441595\n",
            "    test_CER_(Argmax): 0.07907986723164176\n",
            "    test_WER_(Argmax): 0.2501580192506697\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 38 [0/200 (0%)] Loss: 0.028585\n",
            "train:  12% 25/200 [00:14<01:21,  2.15it/s]Train Epoch: 38 [25/200 (12%)] Loss: 0.040005\n",
            "train:  25% 50/200 [00:25<01:07,  2.23it/s]Train Epoch: 38 [50/200 (25%)] Loss: 0.057722\n",
            "train:  38% 75/200 [00:37<00:55,  2.25it/s]Train Epoch: 38 [75/200 (38%)] Loss: 0.031960\n",
            "train:  50% 100/200 [00:49<00:45,  2.21it/s]Train Epoch: 38 [100/200 (50%)] Loss: 0.080721\n",
            "train:  62% 125/200 [01:00<00:33,  2.22it/s]Train Epoch: 38 [125/200 (62%)] Loss: 0.059493\n",
            "train:  75% 150/200 [01:12<00:22,  2.21it/s]Train Epoch: 38 [150/200 (75%)] Loss: 0.033122\n",
            "train:  88% 175/200 [01:24<00:11,  2.25it/s]Train Epoch: 38 [175/200 (88%)] Loss: 0.033127\n",
            "train: 100% 199/200 [01:35<00:00,  2.08it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.98it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.53it/s]\n",
            "    epoch          : 38\n",
            "    loss           : 0.053615109771490095\n",
            "    grad_norm      : 0.4115638303756714\n",
            "    val_loss       : 0.31227005106561323\n",
            "    val_CER_(Argmax): 0.07721248788030224\n",
            "    val_WER_(Argmax): 0.24326886587975322\n",
            "    test_loss      : 0.3271630580832319\n",
            "    test_CER_(Argmax): 0.07749017261919547\n",
            "    test_WER_(Argmax): 0.2460800845948515\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 39 [0/200 (0%)] Loss: 0.030758\n",
            "train:  12% 25/200 [00:12<01:19,  2.21it/s]Train Epoch: 39 [25/200 (12%)] Loss: 0.041187\n",
            "train:  25% 50/200 [00:24<01:08,  2.20it/s]Train Epoch: 39 [50/200 (25%)] Loss: 0.033650\n",
            "train:  38% 75/200 [00:36<00:56,  2.22it/s]Train Epoch: 39 [75/200 (38%)] Loss: 0.034391\n",
            "train:  50% 100/200 [00:48<00:46,  2.17it/s]Train Epoch: 39 [100/200 (50%)] Loss: 0.025458\n",
            "train:  62% 125/200 [01:00<00:34,  2.20it/s]Train Epoch: 39 [125/200 (62%)] Loss: 0.050008\n",
            "train:  75% 150/200 [01:11<00:22,  2.23it/s]Train Epoch: 39 [150/200 (75%)] Loss: 0.055337\n",
            "train:  88% 175/200 [01:23<00:11,  2.16it/s]Train Epoch: 39 [175/200 (88%)] Loss: 0.064791\n",
            "train: 100% 199/200 [01:35<00:00,  2.09it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.63it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 10.58it/s]\n",
            "    epoch          : 39\n",
            "    loss           : 0.05450696580111981\n",
            "    grad_norm      : 0.4200274509191513\n",
            "    val_loss       : 0.3065069943666458\n",
            "    val_CER_(Argmax): 0.0766276825394482\n",
            "    val_WER_(Argmax): 0.2423156155643361\n",
            "    test_loss      : 0.32289288229331736\n",
            "    test_CER_(Argmax): 0.07684831852639015\n",
            "    test_WER_(Argmax): 0.24424318946448156\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 40 [0/200 (0%)] Loss: 0.055976\n",
            "train:  12% 25/200 [00:13<01:18,  2.22it/s]Train Epoch: 40 [25/200 (12%)] Loss: 0.044873\n",
            "train:  25% 50/200 [00:24<01:06,  2.25it/s]Train Epoch: 40 [50/200 (25%)] Loss: 0.033113\n",
            "train:  38% 75/200 [00:36<00:55,  2.24it/s]Train Epoch: 40 [75/200 (38%)] Loss: 0.029605\n",
            "train:  50% 100/200 [00:47<00:44,  2.25it/s]Train Epoch: 40 [100/200 (50%)] Loss: 0.036798\n",
            "train:  62% 125/200 [00:59<00:33,  2.24it/s]Train Epoch: 40 [125/200 (62%)] Loss: 0.038859\n",
            "train:  75% 150/200 [01:11<00:22,  2.20it/s]Train Epoch: 40 [150/200 (75%)] Loss: 0.058629\n",
            "train:  88% 175/200 [01:23<00:11,  2.23it/s]Train Epoch: 40 [175/200 (88%)] Loss: 0.030886\n",
            "train: 100% 199/200 [01:34<00:00,  2.10it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.32it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.40it/s]\n",
            "    epoch          : 40\n",
            "    loss           : 0.06150240860879421\n",
            "    grad_norm      : 0.4610733211040497\n",
            "    val_loss       : 0.3075091786244336\n",
            "    val_CER_(Argmax): 0.0760497643874489\n",
            "    val_WER_(Argmax): 0.24184552206558887\n",
            "    test_loss      : 0.32488458203833276\n",
            "    test_CER_(Argmax): 0.0763939638720974\n",
            "    test_WER_(Argmax): 0.24302752477598796\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 41 [0/200 (0%)] Loss: 0.105479\n",
            "train:  12% 25/200 [00:13<01:26,  2.01it/s]Train Epoch: 41 [25/200 (12%)] Loss: 0.087774\n",
            "train:  25% 50/200 [00:25<01:06,  2.25it/s]Train Epoch: 41 [50/200 (25%)] Loss: 0.053650\n",
            "train:  38% 75/200 [00:37<00:55,  2.23it/s]Train Epoch: 41 [75/200 (38%)] Loss: 0.028217\n",
            "train:  50% 100/200 [00:48<00:44,  2.24it/s]Train Epoch: 41 [100/200 (50%)] Loss: 0.030230\n",
            "train:  62% 125/200 [01:00<00:33,  2.25it/s]Train Epoch: 41 [125/200 (62%)] Loss: 0.024926\n",
            "train:  75% 150/200 [01:12<00:22,  2.25it/s]Train Epoch: 41 [150/200 (75%)] Loss: 0.035201\n",
            "train:  88% 175/200 [01:24<00:11,  2.24it/s]Train Epoch: 41 [175/200 (88%)] Loss: 0.049700\n",
            "train: 100% 199/200 [01:35<00:00,  2.08it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 10.96it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 10.62it/s]\n",
            "    epoch          : 41\n",
            "    loss           : 0.053063366115093234\n",
            "    grad_norm      : 0.42587376952171324\n",
            "    val_loss       : 0.3090207461048575\n",
            "    val_CER_(Argmax): 0.07593239087337118\n",
            "    val_WER_(Argmax): 0.24195994978757426\n",
            "    test_loss      : 0.32505568534862705\n",
            "    test_CER_(Argmax): 0.07668726121471849\n",
            "    test_WER_(Argmax): 0.24501655072372538\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 42 [0/200 (0%)] Loss: 0.070135\n",
            "train:  12% 25/200 [00:11<01:18,  2.22it/s]Train Epoch: 42 [25/200 (12%)] Loss: 0.032689\n",
            "train:  25% 50/200 [00:23<01:07,  2.24it/s]Train Epoch: 42 [50/200 (25%)] Loss: 0.051049\n",
            "train:  38% 75/200 [00:35<00:56,  2.21it/s]Train Epoch: 42 [75/200 (38%)] Loss: 0.076168\n",
            "train:  50% 100/200 [00:46<00:44,  2.24it/s]Train Epoch: 42 [100/200 (50%)] Loss: 0.073808\n",
            "train:  62% 125/200 [00:58<00:34,  2.17it/s]Train Epoch: 42 [125/200 (62%)] Loss: 0.021334\n",
            "train:  75% 150/200 [01:10<00:22,  2.24it/s]Train Epoch: 42 [150/200 (75%)] Loss: 0.031524\n",
            "train:  88% 175/200 [01:21<00:11,  2.24it/s]Train Epoch: 42 [175/200 (88%)] Loss: 0.039579\n",
            "train: 100% 199/200 [01:33<00:00,  2.12it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.70it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.05it/s]\n",
            "    epoch          : 42\n",
            "    loss           : 0.038999228030443193\n",
            "    grad_norm      : 0.36673429667949675\n",
            "    val_loss       : 0.3093937000807594\n",
            "    val_CER_(Argmax): 0.07497592784674154\n",
            "    val_WER_(Argmax): 0.24023686861459875\n",
            "    test_loss      : 0.32542198605653716\n",
            "    test_CER_(Argmax): 0.07581230822858653\n",
            "    test_WER_(Argmax): 0.24134806868721964\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 43 [0/200 (0%)] Loss: 0.054818\n",
            "train:  12% 25/200 [00:13<01:20,  2.16it/s]Train Epoch: 43 [25/200 (12%)] Loss: 0.015158\n",
            "train:  25% 50/200 [00:25<01:07,  2.22it/s]Train Epoch: 43 [50/200 (25%)] Loss: 0.025997\n",
            "train:  38% 75/200 [00:37<00:55,  2.24it/s]Train Epoch: 43 [75/200 (38%)] Loss: 0.041117\n",
            "train:  50% 100/200 [00:49<00:44,  2.22it/s]Train Epoch: 43 [100/200 (50%)] Loss: 0.051682\n",
            "train:  62% 125/200 [01:00<00:33,  2.23it/s]Train Epoch: 43 [125/200 (62%)] Loss: 0.045342\n",
            "train:  75% 150/200 [01:12<00:22,  2.24it/s]Train Epoch: 43 [150/200 (75%)] Loss: 0.038103\n",
            "train:  88% 175/200 [01:24<00:11,  2.19it/s]Train Epoch: 43 [175/200 (88%)] Loss: 0.033712\n",
            "train: 100% 199/200 [01:35<00:00,  2.07it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.39it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 10.74it/s]\n",
            "    epoch          : 43\n",
            "    loss           : 0.0396217430382967\n",
            "    grad_norm      : 0.37819829642772673\n",
            "    val_loss       : 0.3095328145167407\n",
            "    val_CER_(Argmax): 0.07545654470135241\n",
            "    val_WER_(Argmax): 0.2401445859088912\n",
            "    test_loss      : 0.3261593205899727\n",
            "    test_CER_(Argmax): 0.07524937595233858\n",
            "    test_WER_(Argmax): 0.23982341177062758\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 44 [0/200 (0%)] Loss: 0.046026\n",
            "train:  12% 25/200 [00:12<01:18,  2.22it/s]Train Epoch: 44 [25/200 (12%)] Loss: 0.037013\n",
            "train:  25% 50/200 [00:24<01:07,  2.22it/s]Train Epoch: 44 [50/200 (25%)] Loss: 0.050227\n",
            "train:  38% 75/200 [00:36<00:55,  2.25it/s]Train Epoch: 44 [75/200 (38%)] Loss: 0.037154\n",
            "train:  50% 100/200 [00:48<00:45,  2.21it/s]Train Epoch: 44 [100/200 (50%)] Loss: 0.056819\n",
            "train:  62% 125/200 [00:59<00:33,  2.22it/s]Train Epoch: 44 [125/200 (62%)] Loss: 0.055808\n",
            "train:  75% 150/200 [01:11<00:23,  2.09it/s]Train Epoch: 44 [150/200 (75%)] Loss: 0.076281\n",
            "train:  88% 175/200 [01:23<00:11,  2.22it/s]Train Epoch: 44 [175/200 (88%)] Loss: 0.024698\n",
            "train: 100% 199/200 [01:35<00:00,  2.09it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 10.92it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.28it/s]\n",
            "    epoch          : 44\n",
            "    loss           : 0.04587900929152965\n",
            "    grad_norm      : 0.3825070422887802\n",
            "    val_loss       : 0.3100509003681295\n",
            "    val_CER_(Argmax): 0.07466290204714746\n",
            "    val_WER_(Argmax): 0.23735991635574086\n",
            "    test_loss      : 0.3283039654900388\n",
            "    test_CER_(Argmax): 0.07502682669686707\n",
            "    test_WER_(Argmax): 0.23934130399800346\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 45 [0/200 (0%)] Loss: 0.067827\n",
            "train:  12% 25/200 [00:13<01:17,  2.25it/s]Train Epoch: 45 [25/200 (12%)] Loss: 0.059883\n",
            "train:  25% 50/200 [00:24<01:07,  2.22it/s]Train Epoch: 45 [50/200 (25%)] Loss: 0.018382\n",
            "train:  38% 75/200 [00:36<00:56,  2.21it/s]Train Epoch: 45 [75/200 (38%)] Loss: 0.036647\n",
            "train:  50% 100/200 [00:48<00:44,  2.22it/s]Train Epoch: 45 [100/200 (50%)] Loss: 0.030109\n",
            "train:  62% 125/200 [01:00<00:33,  2.23it/s]Train Epoch: 45 [125/200 (62%)] Loss: 0.040621\n",
            "train:  75% 150/200 [01:12<00:22,  2.18it/s]Train Epoch: 45 [150/200 (75%)] Loss: 0.040058\n",
            "train:  88% 175/200 [01:24<00:11,  2.20it/s]Train Epoch: 45 [175/200 (88%)] Loss: 0.044945\n",
            "train: 100% 199/200 [01:36<00:00,  2.06it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.31it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.26it/s]\n",
            "    epoch          : 45\n",
            "    loss           : 0.03618047896772623\n",
            "    grad_norm      : 0.36349295258522035\n",
            "    val_loss       : 0.30738716143019057\n",
            "    val_CER_(Argmax): 0.07395324543716399\n",
            "    val_WER_(Argmax): 0.2364032497675036\n",
            "    test_loss      : 0.32363674062781217\n",
            "    test_CER_(Argmax): 0.07441052838520151\n",
            "    test_WER_(Argmax): 0.23657442895459888\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 46 [0/200 (0%)] Loss: 0.030247\n",
            "train:  12% 25/200 [00:13<01:18,  2.22it/s]Train Epoch: 46 [25/200 (12%)] Loss: 0.017876\n",
            "train:  25% 50/200 [00:24<01:06,  2.25it/s]Train Epoch: 46 [50/200 (25%)] Loss: 0.040244\n",
            "train:  38% 75/200 [00:36<00:56,  2.23it/s]Train Epoch: 46 [75/200 (38%)] Loss: 0.027237\n",
            "train:  50% 100/200 [00:48<00:45,  2.22it/s]Train Epoch: 46 [100/200 (50%)] Loss: 0.056403\n",
            "train:  62% 125/200 [00:59<00:32,  2.29it/s]Train Epoch: 46 [125/200 (62%)] Loss: 0.032293\n",
            "train:  75% 150/200 [01:11<00:22,  2.22it/s]Train Epoch: 46 [150/200 (75%)] Loss: 0.017610\n",
            "train:  88% 175/200 [01:23<00:11,  2.22it/s]Train Epoch: 46 [175/200 (88%)] Loss: 0.017926\n",
            "train: 100% 199/200 [01:35<00:00,  2.09it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.51it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 10.82it/s]\n",
            "    epoch          : 46\n",
            "    loss           : 0.036799449771642685\n",
            "    grad_norm      : 0.3484828573465347\n",
            "    val_loss       : 0.3083181808976566\n",
            "    val_CER_(Argmax): 0.07418631678972144\n",
            "    val_WER_(Argmax): 0.23623023203871077\n",
            "    test_loss      : 0.3254525972212233\n",
            "    test_CER_(Argmax): 0.07409743379710607\n",
            "    test_WER_(Argmax): 0.2371294359122239\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 47 [0/200 (0%)] Loss: 0.081921\n",
            "train:  12% 25/200 [00:12<01:18,  2.22it/s]Train Epoch: 47 [25/200 (12%)] Loss: 0.056528\n",
            "train:  25% 50/200 [00:24<01:06,  2.26it/s]Train Epoch: 47 [50/200 (25%)] Loss: 0.067053\n",
            "train:  38% 75/200 [00:35<00:55,  2.24it/s]Train Epoch: 47 [75/200 (38%)] Loss: 0.018470\n",
            "train:  50% 100/200 [00:47<00:46,  2.16it/s]Train Epoch: 47 [100/200 (50%)] Loss: 0.053225\n",
            "train:  62% 125/200 [00:59<00:33,  2.21it/s]Train Epoch: 47 [125/200 (62%)] Loss: 0.027193\n",
            "train:  75% 150/200 [01:11<00:22,  2.27it/s]Train Epoch: 47 [150/200 (75%)] Loss: 0.018944\n",
            "train:  88% 175/200 [01:22<00:11,  2.25it/s]Train Epoch: 47 [175/200 (88%)] Loss: 0.034990\n",
            "train: 100% 199/200 [01:34<00:00,  2.10it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.59it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.19it/s]\n",
            "    epoch          : 47\n",
            "    loss           : 0.03918648511171341\n",
            "    grad_norm      : 0.3572318136692047\n",
            "    val_loss       : 0.307271626942298\n",
            "    val_CER_(Argmax): 0.07408687717300776\n",
            "    val_WER_(Argmax): 0.23585214791588868\n",
            "    test_loss      : 0.32449414381166786\n",
            "    test_CER_(Argmax): 0.07394536355453092\n",
            "    test_WER_(Argmax): 0.23635880304023785\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 48 [0/200 (0%)] Loss: 0.044207\n",
            "train:  12% 25/200 [00:13<01:21,  2.16it/s]Train Epoch: 48 [25/200 (12%)] Loss: 0.020889\n",
            "train:  25% 50/200 [00:24<01:06,  2.24it/s]Train Epoch: 48 [50/200 (25%)] Loss: 0.009512\n",
            "train:  38% 75/200 [00:36<00:56,  2.22it/s]Train Epoch: 48 [75/200 (38%)] Loss: 0.059520\n",
            "train:  50% 100/200 [00:47<00:44,  2.23it/s]Train Epoch: 48 [100/200 (50%)] Loss: 0.014937\n",
            "train:  62% 125/200 [00:59<00:33,  2.22it/s]Train Epoch: 48 [125/200 (62%)] Loss: 0.022703\n",
            "train:  75% 150/200 [01:11<00:22,  2.22it/s]Train Epoch: 48 [150/200 (75%)] Loss: 0.033235\n",
            "train:  88% 175/200 [01:22<00:11,  2.23it/s]Train Epoch: 48 [175/200 (88%)] Loss: 0.036878\n",
            "train: 100% 199/200 [01:34<00:00,  2.10it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.20it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 11.29it/s]\n",
            "    epoch          : 48\n",
            "    loss           : 0.037649055458605286\n",
            "    grad_norm      : 0.37623927623033526\n",
            "    val_loss       : 0.31034605766043943\n",
            "    val_CER_(Argmax): 0.07398743087033736\n",
            "    val_WER_(Argmax): 0.23628357793335403\n",
            "    test_loss      : 0.3279341617371978\n",
            "    test_CER_(Argmax): 0.07423744618378707\n",
            "    test_WER_(Argmax): 0.23732151583937705\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 49 [0/200 (0%)] Loss: 0.031328\n",
            "train:  12% 25/200 [00:11<01:17,  2.25it/s]Train Epoch: 49 [25/200 (12%)] Loss: 0.016382\n",
            "train:  25% 50/200 [00:23<01:06,  2.25it/s]Train Epoch: 49 [50/200 (25%)] Loss: 0.016466\n",
            "train:  38% 75/200 [00:34<00:55,  2.24it/s]Train Epoch: 49 [75/200 (38%)] Loss: 0.032495\n",
            "train:  50% 100/200 [00:46<00:44,  2.24it/s]Train Epoch: 49 [100/200 (50%)] Loss: 0.041731\n",
            "train:  62% 125/200 [00:58<00:34,  2.21it/s]Train Epoch: 49 [125/200 (62%)] Loss: 0.018443\n",
            "train:  75% 150/200 [01:10<00:22,  2.20it/s]Train Epoch: 49 [150/200 (75%)] Loss: 0.026787\n",
            "train:  88% 175/200 [01:22<00:11,  2.23it/s]Train Epoch: 49 [175/200 (88%)] Loss: 0.039076\n",
            "train: 100% 199/200 [01:34<00:00,  2.11it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.76it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 10.93it/s]\n",
            "    epoch          : 49\n",
            "    loss           : 0.04186433956027031\n",
            "    grad_norm      : 0.38394062757492065\n",
            "    val_loss       : 0.3072378521456438\n",
            "    val_CER_(Argmax): 0.0737659817324482\n",
            "    val_WER_(Argmax): 0.2349990020057228\n",
            "    test_loss      : 0.3249053720657418\n",
            "    test_CER_(Argmax): 0.0741084881549873\n",
            "    test_WER_(Argmax): 0.2364825078348759\n",
            "Saving current best: model_best.pth ...\n",
            "train:   0% 0/200 [00:00<?, ?it/s]Train Epoch: 50 [0/200 (0%)] Loss: 0.060550\n",
            "train:  12% 25/200 [00:15<01:18,  2.23it/s]Train Epoch: 50 [25/200 (12%)] Loss: 0.029308\n",
            "train:  25% 50/200 [00:27<01:07,  2.22it/s]Train Epoch: 50 [50/200 (25%)] Loss: 0.047798\n",
            "train:  38% 75/200 [00:38<00:55,  2.25it/s]Train Epoch: 50 [75/200 (38%)] Loss: 0.062049\n",
            "train:  50% 100/200 [00:50<00:45,  2.19it/s]Train Epoch: 50 [100/200 (50%)] Loss: 0.027228\n",
            "train:  62% 125/200 [01:02<00:33,  2.25it/s]Train Epoch: 50 [125/200 (62%)] Loss: 0.057213\n",
            "train:  75% 150/200 [01:14<00:22,  2.22it/s]Train Epoch: 50 [150/200 (75%)] Loss: 0.047839\n",
            "train:  88% 175/200 [01:25<00:11,  2.22it/s]Train Epoch: 50 [175/200 (88%)] Loss: 0.034520\n",
            "train: 100% 199/200 [01:37<00:00,  2.03it/s]\n",
            "val: 100% 85/85 [00:07<00:00, 11.45it/s]\n",
            "test: 100% 82/82 [00:07<00:00, 10.57it/s]\n",
            "    epoch          : 50\n",
            "    loss           : 0.036053226105868814\n",
            "    grad_norm      : 0.38016326785087584\n",
            "    val_loss       : 0.3064143683980493\n",
            "    val_CER_(Argmax): 0.0737868965134652\n",
            "    val_WER_(Argmax): 0.23476641538878662\n",
            "    test_loss      : 0.3236164621463636\n",
            "    test_CER_(Argmax): 0.07383018462001767\n",
            "    test_WER_(Argmax): 0.23529361115330422\n",
            "Saving current best: model_best.pth ...\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: ðŸš€ View run \u001b[33mtesting\u001b[0m at: \u001b[34mhttps://wandb.ai/vadim-smir97-simon-fraser-university/ASR_HW/runs/9cwgliuq\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250123_045152-9cwgliuq/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 inference.py -cn=inference"
      ],
      "metadata": {
        "id": "vdzJJZryV90X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "023a60fb-a926-47f7-86b5-97cf3cc54503"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading language model...\n",
            "\n",
            "Language model successfully downloaded!\n",
            "Downloading vocabulary...\n",
            "\n",
            "Vocabulary successfully downloaded!\n",
            "Loading the LM will be faster if you build a binary file.\n",
            "Reading /content/asr_hw/data/libri_lm/lowercase_3e-7.arpa\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "DeepSpeech2(\n",
            "  (conv_block): ConvBlock(\n",
            "    (conv_block): Sequential(\n",
            "      (0): Conv2d(1, 32, kernel_size=(41, 11), stride=(2, 2), padding=(20, 5))\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): Hardtanh(min_val=0, max_val=20, inplace=True)\n",
            "      (3): Conv2d(32, 32, kernel_size=(21, 11), stride=(2, 1), padding=(10, 5))\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): Hardtanh(min_val=0, max_val=20, inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (gru_layers): Sequential(\n",
            "    (0): GRUBlock(\n",
            "      (gru): GRU(1024, 1024, batch_first=True, bidirectional=True)\n",
            "    )\n",
            "    (1): BatchNormT(\n",
            "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): GRUBlock(\n",
            "      (gru): GRU(1024, 1024, batch_first=True, bidirectional=True)\n",
            "    )\n",
            "    (3): BatchNormT(\n",
            "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (4): GRUBlock(\n",
            "      (gru): GRU(1024, 1024, batch_first=True, bidirectional=True)\n",
            "    )\n",
            "    (5): BatchNormT(\n",
            "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (6): GRUBlock(\n",
            "      (gru): GRU(1024, 1024, batch_first=True, bidirectional=True)\n",
            "    )\n",
            "    (7): BatchNormT(\n",
            "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (8): GRUBlock(\n",
            "      (gru): GRU(1024, 1024, batch_first=True, bidirectional=True)\n",
            "    )\n",
            "  )\n",
            "  (batch_norm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc): Linear(in_features=1024, out_features=28, bias=False)\n",
            ")\n",
            "All parameters: 63266080\n",
            "Trainable parameters: 63266080\n",
            "Loading model weights from: data/models/model_best.pth ...\n",
            "Downloading the best model...\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1YBZZfyJf9S8dwhT2XBiIZR6LM6CFbWnU\n",
            "From (redirected): https://drive.google.com/uc?id=1YBZZfyJf9S8dwhT2XBiIZR6LM6CFbWnU&confirm=t&uuid=164f7751-34bd-4641-9199-11e86ccf2a76\n",
            "To: /content/asr_hw/data/models/model_best.pth\n",
            "100% 759M/759M [00:10<00:00, 73.7MB/s]\n",
            "\n",
            "Best model successfully downloaded!\n",
            "test: 100% 82/82 [01:02<00:00,  1.31it/s]\n",
            "    test_CER_(Argmax): 0.07413463661593472\n",
            "    test_WER_(Argmax): 0.23709396768903815\n",
            "    test_CER_(LM-BeamSearch): 0.06139948323314231\n",
            "    test_WER_(LM-BeamSearch): 0.164760857707281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qQuxnfkYTq4t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}